{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "food_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnandaIlyasa/bangkit-capstone-bahanbaku/blob/3-combined-dataset/notebooks/food_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import modules"
      ],
      "metadata": {
        "id": "WI1OiwZLWKBl"
      }
    },
    {
      "metadata": {
        "id": "suJ5vUhtcK69"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB7\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import collections\n",
        "from collections import defaultdict\n",
        "\n",
        "from shutil import copy\n",
        "from shutil import copytree, rmtree\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download food-101 dataset and extract"
      ],
      "metadata": {
        "id": "HO33I-wnWdtB"
      }
    },
    {
      "metadata": {
        "id": "f88XvEBTQBS9"
      },
      "cell_type": "code",
      "source": [
        "def get_data_extract():\n",
        "  if \"food-101\" in os.listdir():\n",
        "    print(\"Dataset already exists\")\n",
        "  else:\n",
        "    tf.keras.utils.get_file(\n",
        "    'food-101.tar.gz',\n",
        "    'http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz',\n",
        "    cache_subdir='/content',\n",
        "    extract=True,\n",
        "    archive_format='tar',\n",
        "    cache_dir=None\n",
        "    )\n",
        "    print(\"Dataset downloaded and extracted!\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O7kY0v23QJGO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "415ac6fe-9765-465d-8943-1160c46a74f9"
      },
      "cell_type": "code",
      "source": [
        "get_data_extract()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
            "4996284416/4996278331 [==============================] - 184s 0us/step\n",
            "4996292608/4996278331 [==============================] - 184s 0us/step\n",
            "Dataset downloaded and extracted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount drive to save checkpoint and load dataset"
      ],
      "metadata": {
        "id": "nUxDK-2xhfab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "V1kXkurx4LLv",
        "outputId": "01885909-a9cb-4483-cb0b-d29777151150",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download additional Indonesian food dataset from kaggle"
      ],
      "metadata": {
        "id": "21v-F4lQaiuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpVgZj-flBg4",
        "outputId": "eda1eff9-99f9-4d1b-91c4-0c4237f1878f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.5.18.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "YBW11KWellD2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Required to upload kaggle.json file first to current directory (/content)\n",
        "-- kaggle.json file contains api token and can be downloaded from kaggle acount page"
      ],
      "metadata": {
        "id": "cHBByo2wa2N4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "KpEQrC033Ha7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define subset of food classes that will be used and create separate folders to store them"
      ],
      "metadata": {
        "id": "0qKldaRUaIAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "FSaNJzlh3Sc0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download local food datasets from kaggle and extract"
      ],
      "metadata": {
        "id": "LIBp0l6tccFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d theresalusiana/indonesian-food"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz54_XACilUL",
        "outputId": "f69a7237-14f4-4b73-ca05-0f5ef6c52840"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading indonesian-food.zip to /content\n",
            " 99% 666M/673M [00:05<00:00, 103MB/s]\n",
            "100% 673M/673M [00:05<00:00, 124MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d arizbw/traditional-food-knowledge-of-indonesia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orIH5LSUxnHg",
        "outputId": "a0db497e-e152-4d12-bda0-3ab9714ff487"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading traditional-food-knowledge-of-indonesia.zip to /content\n",
            "100% 3.10G/3.10G [00:23<00:00, 164MB/s]\n",
            "100% 3.10G/3.10G [00:23<00:00, 141MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip -q /content/indonesian-food.zip"
      ],
      "metadata": {
        "id": "EEDPnP5U2fBU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Required to upload kaggle.json file first to current directory (/content)\n",
        "-- kaggle.json file contains api token and can be downloaded from kaggle acount page"
      ],
      "metadata": {
        "id": "cHBByo2wa2N4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip -q /content/traditional-food-knowledge-of-indonesia.zip"
      ],
      "metadata": {
        "id": "rBd0kIQVxr2n"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create combined_dataset folder to accommodate all data from different datasets"
      ],
      "metadata": {
        "id": "CRA79-1Dzv9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ./combined_dataset"
      ],
      "metadata": {
        "id": "VIMme5MxyzLw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing food-tfk-images datasets so that each food class has it's own folder"
      ],
      "metadata": {
        "id": "wC3AdAYzx-qD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_food_img_data(filepath, src, dest):\n",
        "  image_classes = defaultdict(list)\n",
        "  with open(filepath, 'r') as csv:\n",
        "      csv.readline()\n",
        "      lines = [read.strip() for read in csv.readlines()]\n",
        "      for line in lines:\n",
        "        file_desc = line.split(',')[:3]\n",
        "        image_classes[file_desc[2]].append(file_desc[0])\n",
        "\n",
        "  if not os.path.exists(dest):\n",
        "    os.makedirs(dest)\n",
        "\n",
        "  for food in image_classes.keys():\n",
        "    if not os.path.exists(os.path.join(dest,food)):\n",
        "      os.makedirs(os.path.join(dest,food))\n",
        "    for i in image_classes[food]:\n",
        "      copy(os.path.join(src,i), os.path.join(dest,food,i))\n",
        "  print(\"Copying Done!\")\n",
        "  # return image_classes"
      ],
      "metadata": {
        "id": "esVEjHaBx8ca"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy food-tfk-images dataset to combined_dataset folder"
      ],
      "metadata": {
        "id": "XxqARil96rOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Preparing food-tfk-images datasets...\")\n",
        "prepare_food_img_data('/content/train.csv', '/content/food-tfk-images', '/content/combined_dataset')\n",
        "prepare_food_img_data('/content/dev.csv', '/content/food-tfk-images', '/content/combined_dataset')\n",
        "prepare_food_img_data('/content/test.csv', '/content/food-tfk-images', '/content/combined_dataset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SWzERhVy-pm",
        "outputId": "e685cb47-d660-4388-d3b4-8ddc4974a2aa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing food-tfk-images datasets...\n",
            "Copying Done!\n",
            "Copying Done!\n",
            "Copying Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy indonesian-food dataset to combined_dataset folder"
      ],
      "metadata": {
        "id": "pp-MFRrXdLID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, rename gado to gado-gado to standardize"
      ],
      "metadata": {
        "id": "YkVfFnKM3JMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mv /content/dataset/train/gado /content/dataset/train/gado-gado"
      ],
      "metadata": {
        "id": "LuRfCu903B5Y"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mv /content/dataset/test/gado /content/dataset/test/gado-gado"
      ],
      "metadata": {
        "id": "xP2lfLZqBd-z"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mv /content/dataset/valid/gado /content/dataset/valid/gado-gado"
      ],
      "metadata": {
        "id": "Rlpd13sCBe5J"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp -a /content/dataset/train/gado-gado/. /content/combined_dataset/gado-gado"
      ],
      "metadata": {
        "id": "59tY3oEOiyZz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp -a /content/dataset/train/gudeg/. /content/combined_dataset/gudeg"
      ],
      "metadata": {
        "id": "FGAAAEo2ixq4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp -a /content/dataset/train/rendang/. /content/combined_dataset/rendang"
      ],
      "metadata": {
        "id": "tjBDj5wj1Lsu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp -a /content/dataset/test/gado-gado/. /content/combined_dataset/gado-gado"
      ],
      "metadata": {
        "id": "UcuH2tXC1a_F"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp -a /content/dataset/test/gudeg/. /content/combined_dataset/gudeg"
      ],
      "metadata": {
        "id": "qh5waDcF1a_F"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp -a /content/dataset/test/rendang/. /content/combined_dataset/rendang"
      ],
      "metadata": {
        "id": "DDFcSyvy1a_G"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp -a /content/dataset/valid/gado-gado/. /content/combined_dataset/gado-gado"
      ],
      "metadata": {
        "id": "GVcgxrHT1fZj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp -a /content/dataset/valid/gudeg/. /content/combined_dataset/gudeg"
      ],
      "metadata": {
        "id": "AcsToZTt1fZj"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp -a /content/dataset/valid/rendang/. /content/combined_dataset/rendang"
      ],
      "metadata": {
        "id": "3B9EGL3c1fZj"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp -a /content/dataset/train/. /content/combined_dataset"
      ],
      "metadata": {
        "id": "Bnex8ZBt4N0p"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp -a /content/dataset/test/. /content/combined_dataset"
      ],
      "metadata": {
        "id": "Pv7JGlBs1xkc"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if indonesian food dataset already in food-101 folder how many bakso images are there"
      ],
      "metadata": {
        "id": "xE90Q1koc9wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! cp -a /content/dataset/valid/. /content/combined_dataset"
      ],
      "metadata": {
        "id": "UJhZT2fb110R"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/combined_dataset/bakso | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDWC96FD4_VH",
        "outputId": "c8fddd89-21f5-4ca3-849f-805d1e7daa1b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy subset of food-101 dataset to combined_dataset folder"
      ],
      "metadata": {
        "id": "HQpuFgEK3rSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def copy_subset_dataset_to_combined(food_list, src, dest):\n",
        "  for food_item in food_list :\n",
        "    if not os.path.exists(os.path.join(dest,food_item)):\n",
        "      print(\"Copying images into \",food_item)\n",
        "      copytree(os.path.join(src,food_item), os.path.join(dest,food_item))\n",
        "    else :\n",
        "      print(\"Copying images into \",food_item)\n",
        "      for i in os.listdir(os.path.join(src,food_item)):\n",
        "        copy(os.path.join(src,food_item,i), os.path.join(dest,food_item,i))"
      ],
      "metadata": {
        "id": "pTaOWEKi3qb8"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "food_101_subset = ['apple_pie', 'bibimbap', 'bread_pudding', 'cheesecake', 'chicken_curry', 'chicken_wings', 'chocolate_cake', 'french_fries', 'garlic_bread', 'gnocchi', 'hamburger', 'omelette', 'pizza', 'samosa', 'shrimp_and_grits', 'strawberry_shortcake', 'tacos', 'tiramisu', 'tuna_tartare', 'waffles']\n",
        "copy_subset_dataset_to_combined(food_101_subset, '/content/food-101/images', '/content/combined_dataset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFyd1eS47iWT",
        "outputId": "4bdf368e-573d-4b15-952d-05b090192d0c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying images into  apple_pie\n",
            "Copying images into  bibimbap\n",
            "Copying images into  bread_pudding\n",
            "Copying images into  cheesecake\n",
            "Copying images into  chicken_curry\n",
            "Copying images into  chicken_wings\n",
            "Copying images into  chocolate_cake\n",
            "Copying images into  french_fries\n",
            "Copying images into  garlic_bread\n",
            "Copying images into  gnocchi\n",
            "Copying images into  hamburger\n",
            "Copying images into  omelette\n",
            "Copying images into  pizza\n",
            "Copying images into  samosa\n",
            "Copying images into  shrimp_and_grits\n",
            "Copying images into  strawberry_shortcake\n",
            "Copying images into  tacos\n",
            "Copying images into  tiramisu\n",
            "Copying images into  tuna_tartare\n",
            "Copying images into  waffles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get food labels"
      ],
      "metadata": {
        "id": "YNhLW03yW4Bn"
      }
    },
    {
      "metadata": {
        "id": "Jfif27Pr5KEn",
        "outputId": "f7254316-280d-4860-96e7-4fe6f5b2a342",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/combined_dataset\"\n",
        "all_foods_sorted = sorted(os.listdir(data_dir))\n",
        "for food in all_foods_sorted:\n",
        "  print(f'\\\"{food}', end=\"\\\", \")\n",
        "print()\n",
        "print(len(all_foods_sorted))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"apple_pie\", \"asinan-jakarta\", \"ayam-betutu\", \"ayam-bumbu-rujak\", \"ayam-goreng-lengkuas\", \"bakso\", \"bibimbap\", \"bika-ambon\", \"bir-pletok\", \"bread_pudding\", \"bubur-manado\", \"cendol\", \"cheesecake\", \"chicken_curry\", \"chicken_wings\", \"chocolate_cake\", \"es-dawet\", \"french_fries\", \"gado-gado\", \"garlic_bread\", \"gnocchi\", \"gudeg\", \"gulai-ikan-mas\", \"hamburger\", \"keladi\", \"kerak-telor\", \"klappertart\", \"kolak\", \"kue-lumpur\", \"kunyit-asam\", \"laksa-bogor\", \"lumpia-semarang\", \"mie-aceh\", \"nagasari\", \"omelette\", \"papeda\", \"pempek-palembang\", \"pizza\", \"rawon-surabaya\", \"rendang\", \"rujak-cingur\", \"samosa\", \"sate\", \"sate-ayam-madura\", \"sate-lilit\", \"sate-maranggi\", \"shrimp_and_grits\", \"soerabi\", \"soto-ayam-lamongan\", \"soto-banjar\", \"strawberry_shortcake\", \"tacos\", \"tahu-telur\", \"tiramisu\", \"tuna_tartare\", \"waffles\", \n",
            "56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing Data (Transform and Load data from directory)"
      ],
      "metadata": {
        "id": "oYsbS0yzfHM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# n_classes,num_epochs, nb_train_samples,nb_validation_samples = 25, 2, train_files, test_files\n",
        "def prepare_data_input_pipeline():\n",
        "  K.clear_session()\n",
        "\n",
        "  img_width, img_height = 150, 150\n",
        "  data_dir = './combined_dataset'\n",
        "\n",
        "  datagen = ImageDataGenerator(\n",
        "      preprocessing_function=preprocess_input,\n",
        "      shear_range=0.2,\n",
        "      validation_split=0.06,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True)\n",
        "\n",
        "  train_generator = datagen.flow_from_directory(\n",
        "      data_dir,\n",
        "      target_size=(img_height, img_width),\n",
        "      batch_size=30,\n",
        "      subset='training',\n",
        "      class_mode='categorical')\n",
        "\n",
        "  validation_generator = datagen.flow_from_directory(\n",
        "      data_dir,\n",
        "      target_size=(img_height, img_width),\n",
        "      batch_size=30,\n",
        "      subset='validation',\n",
        "      class_mode='categorical')\n",
        "  \n",
        "  return train_generator, validation_generator"
      ],
      "metadata": {
        "id": "E3eeFpFeACzu"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load pre-trained model, take some layers from it, and define additional layer on top of it"
      ],
      "metadata": {
        "id": "UQg5rxE0gpNT"
      }
    },
    {
      "metadata": {
        "id": "MS5NI8Py77sA"
      },
      "cell_type": "code",
      "source": [
        "# for layer in inception.layers:\n",
        "#   layer.trainable = False\n",
        "# last_layer = inception.get_layer('mixed7')\n",
        "# last_output = last_layer.output\n",
        "def prepare_model(n_classes):\n",
        "  # bestmodel_path = 'bestmodel_'+str(n_classes)+'class.hdf5'\n",
        "\n",
        "  efficient_net = EfficientNetB7(weights='imagenet', include_top=False, classes=n_classes)\n",
        "  for layer in efficient_net.layers:\n",
        "    layer.trainable = False\n",
        "  last_layer = efficient_net.get_layer('block6a_project_conv')\n",
        "  last_output = last_layer.output\n",
        "\n",
        "  x = last_output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  x = Dropout(0.3)(x)               \n",
        "  x = Dense(n_classes, activation='softmax')(x) \n",
        "  model = Model(efficient_net.input, x)\n",
        "\n",
        "  optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "  model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model and create checkpoint to continue the training later"
      ],
      "metadata": {
        "id": "kpXkODL4hFgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes=len(all_foods_sorted) #56\n",
        "\n",
        "train_generator, validation_generator = prepare_data_input_pipeline()\n",
        "\n",
        "model = prepare_model(n_classes)\n",
        "\n",
        "checkpoint = callbacks.ModelCheckpoint('/content/drive/MyDrive/Google_Bangkit/capstone/checkpoint_'+str(n_classes)+'_classes', save_best_only=True)\n",
        "\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "UBAZCnWXOw1I",
        "outputId": "c70090eb-017f-4b42-fc68-c0ad0ea7b123",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28907 images belonging to 56 classes.\n",
            "Found 1825 images belonging to 56 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continue training from the checkpoint"
      ],
      "metadata": {
        "id": "3rLxC3TihWEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator,\n",
        "                    validation_data=validation_generator,\n",
        "                    epochs=5,\n",
        "                    verbose=1,\n",
        "                    callbacks=[checkpoint])\n",
        "\n",
        "# model.save_weights('weights')\n",
        "# class_map = train_generator.class_indices"
      ],
      "metadata": {
        "id": "EE1BRC-JA_wQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41dec17e-cd46-4a07-cdc3-63211f5126d9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "964/964 [==============================] - ETA: 0s - loss: 1.2260 - accuracy: 0.6459INFO:tensorflow:Assets written to: /content/drive/MyDrive/Google_Bangkit/capstone/checkpoint_56_classes/assets\n",
            "964/964 [==============================] - 516s 518ms/step - loss: 1.2260 - accuracy: 0.6459 - val_loss: 0.8642 - val_accuracy: 0.7386\n",
            "Epoch 2/5\n",
            "964/964 [==============================] - ETA: 0s - loss: 0.8669 - accuracy: 0.7365INFO:tensorflow:Assets written to: /content/drive/MyDrive/Google_Bangkit/capstone/checkpoint_56_classes/assets\n",
            "964/964 [==============================] - 492s 510ms/step - loss: 0.8669 - accuracy: 0.7365 - val_loss: 0.8279 - val_accuracy: 0.7518\n",
            "Epoch 3/5\n",
            "964/964 [==============================] - ETA: 0s - loss: 0.7807 - accuracy: 0.7573INFO:tensorflow:Assets written to: /content/drive/MyDrive/Google_Bangkit/capstone/checkpoint_56_classes/assets\n",
            "964/964 [==============================] - 489s 507ms/step - loss: 0.7807 - accuracy: 0.7573 - val_loss: 0.8131 - val_accuracy: 0.7595\n",
            "Epoch 4/5\n",
            "964/964 [==============================] - ETA: 0s - loss: 0.7187 - accuracy: 0.7766INFO:tensorflow:Assets written to: /content/drive/MyDrive/Google_Bangkit/capstone/checkpoint_56_classes/assets\n",
            "964/964 [==============================] - 485s 504ms/step - loss: 0.7187 - accuracy: 0.7766 - val_loss: 0.7485 - val_accuracy: 0.7710\n",
            "Epoch 5/5\n",
            "964/964 [==============================] - 413s 429ms/step - loss: 0.6661 - accuracy: 0.7893 - val_loss: 0.7784 - val_accuracy: 0.7573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continue training from the checkpoint"
      ],
      "metadata": {
        "id": "3rLxC3TihWEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# continue training\n",
        "n_classes=len(all_foods_sorted) #56\n",
        "train_generator, validation_generator = prepare_data_input_pipeline()\n",
        "checkpoint = callbacks.ModelCheckpoint('/content/drive/MyDrive/Google_Bangkit/capstone/checkpoint_'+str(n_classes)+'_classes', save_best_only=True)\n",
        "loaded_model = load_model('/content/drive/MyDrive/Google_Bangkit/capstone/checkpoint_'+str(n_classes)+'_classes') # checkpoint folder from gdrive\n",
        "new_history = loaded_model.fit(train_generator,\n",
        "                    validation_data=validation_generator,\n",
        "                    epochs=5,\n",
        "                    verbose=1,\n",
        "                    callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVHpJCB_0Fxm",
        "outputId": "100b7451-d4a0-4693-aa40-4ddfbed25b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28907 images belonging to 56 classes.\n",
            "Found 1825 images belonging to 56 classes.\n",
            "Epoch 1/5\n",
            "964/964 [==============================] - ETA: 0s - loss: 0.5442 - accuracy: 0.8265INFO:tensorflow:Assets written to: /content/drive/MyDrive/Google_Bangkit/capstone/checkpoint_56_classes/assets\n",
            "964/964 [==============================] - 535s 540ms/step - loss: 0.5442 - accuracy: 0.8265 - val_loss: 0.7865 - val_accuracy: 0.7693\n",
            "Epoch 2/5\n",
            "512/964 [==============>...............] - ETA: 3:12 - loss: 0.4837 - accuracy: 0.8445"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "KbDzLAHGpJXQ"
      },
      "cell_type": "markdown",
      "source": [
        "# Visualize the accuracy and loss plots"
      ]
    },
    {
      "metadata": {
        "id": "SjRm_AWZpPZm"
      },
      "cell_type": "code",
      "source": [
        "def plot_accuracy(history,title):\n",
        "    plt.title(title)\n",
        "    plt.plot(history.history['accuracy']) # change acc to accuracy if testing TF 2.0\n",
        "    plt.plot(history.history['val_accuracy']) # change val_accuracy if testing TF 2.0\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_loss(history,title):\n",
        "    plt.title(title)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_loss', 'validation_loss'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "plot_accuracy(new_history,'accuracy')\n",
        "plot_loss(new_history,'loss')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}